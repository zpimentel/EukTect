{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0bdacb-dc53-4b96-988d-ebcfae45f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de0e3a-cece-4b1f-9eed-35bd136e9d8f",
   "metadata": {},
   "source": [
    "Make directories and read in list of kmers (used to ensure correct order), the model, and the RefSeq genome summary table (pre-classified as to which one is eukaryotic, bacterial, archael, or viral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aed5952-122e-46d5-ba5b-5c8fa2fa5b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpimentel/miniconda3/envs/VirTect/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./Validation_genomes'):\n",
    "    os.makedirs('./Validation_genomes')\n",
    "\n",
    "df = pd.read_csv(\"assembly_summary_refseq_labeled.csv\")\n",
    "clf = pickle.load(open(\"kmer_SVM.sav\", 'rb'))\n",
    "kmer_list = pickle.load(open(\"kmer_list.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057348e-74a6-4cab-9a13-2b5564381903",
   "metadata": {},
   "source": [
    "Download 10 eukaryotic and 10 bacterial genomes to test. Note: While I am only testing 10 of each, I break up these genomes into smaller contigs and thus end up with thousands of contigs I am actually testing. Another way to approach this could be to download more genomes and sample less contigs from each genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacbe7d7-eee3-499a-b35e-f399cbe60155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_euks = df[df['Classification'] == 'eukaryote'].sample(10, random_state=100)\n",
    "sampled_bact = df[df['Classification'] == 'bacteria'].sample(10, random_state=200)\n",
    "\n",
    "sampled_euks['# assembly_accession'] = sampled_euks['# assembly_accession'].str.split('.').str[0]\n",
    "sampled_bact['# assembly_accession'] = sampled_bact['# assembly_accession'].str.split('.').str[0]\n",
    "\n",
    "sampled_euks_list = sampled_euks['# assembly_accession'].to_list()\n",
    "sampled_bact_list = sampled_bact['# assembly_accession'].to_list()\n",
    "\n",
    "for ftp in sampled_euks['ftp_path'].to_list():\n",
    "    genome_id = ftp.split(\"/\")[-1]\n",
    "    gen_url = os.path.join(ftp,genome_id + \"_genomic.fna.gz\").replace(\" \", \"_\")\n",
    "    r = requests.get(gen_url, allow_redirects=True)\n",
    "    open(\"Validation_genomes/\" + genome_id + \".fna.gzip\", 'wb').write(r.content)\n",
    "\n",
    "for ftp in sampled_bact['ftp_path'].to_list():\n",
    "    genome_id = ftp.split(\"/\")[-1]\n",
    "    gen_url = os.path.join(ftp,genome_id + \"_genomic.fna.gz\").replace(\" \", \"_\")\n",
    "    r = requests.get(gen_url, allow_redirects=True)\n",
    "    open(\"Validation_genomes/\" + genome_id + \".fna.gzip\", 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813b369-f461-4497-9481-377fda19c5c3",
   "metadata": {},
   "source": [
    "Compute the canonical 5-mers from the downloaded genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69a3851-025a-4cc9-aa4f-fb14efd67a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_000002415 euk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpimentel/miniconda3/envs/VirTect/lib/python3.6/site-packages/Bio/Seq.py:155: BiopythonWarning: Biopython Seq objects now use string comparison. Older versions of Biopython used object comparison. During this transition, please use hash(id(my_seq)) or my_dict[id(my_seq)] if you want the old behaviour, or use hash(str(my_seq)) or my_dict[str(my_seq)] for the new string hashing behaviour.\n",
      "  \"the new string hashing behaviour.\", BiopythonWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_000313135 euk\n",
      "GCF_000325025 bact\n",
      "GCF_000523455 euk\n",
      "GCF_000955945 euk\n",
      "GCF_000986985 bact\n",
      "GCF_001500285 euk\n",
      "GCF_001548555 euk\n",
      "GCF_001613715 bact\n",
      "GCF_002000525 bact\n",
      "GCF_002512915 bact\n",
      "GCF_003086295 euk\n",
      "GCF_008831285 euk\n",
      "GCF_009648635 bact\n",
      "GCF_013052645 euk\n",
      "GCF_017639745 euk\n",
      "GCF_017920825 bact\n",
      "GCF_018350345 bact\n",
      "GCF_020163235 bact\n",
      "GCF_900179305 bact\n"
     ]
    }
   ],
   "source": [
    "def is_valid_sequence(seq):\n",
    "    ''' Used to remove any kmers with N's in them '''\n",
    "    return set(seq).issubset({\"A\", \"T\", \"C\", \"G\"})\n",
    "\n",
    "kmer_dict = defaultdict(lambda:0)\n",
    "contigs = set(\" \")\n",
    "\n",
    "directory = \"./Validation_genomes\"\n",
    "euk_count = 0\n",
    "bact_count = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".fna.gzip\"):\n",
    "        genome_bp_count = 0\n",
    "        \n",
    "        genome_id = \"_\".join(filename.split(\"_\")[0:2]).split('.')[0]\n",
    "        \n",
    "        if genome_id in sampled_euks_list: genome_type = 'euk'\n",
    "        elif genome_id in sampled_bact_list: genome_type = 'bact'\n",
    "        else: genome_type = 'NA'\n",
    "            \n",
    "        print(genome_id, genome_type)\n",
    "        \n",
    "        with gzip.open(os.path.join(directory, filename), \"rt\") as handle:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                if genome_bp_count < 1000000:\n",
    "                    if len(record.seq) >= 50000:\n",
    "                        for i in range(0, len(record.seq), 50000):\n",
    "                            genome_bp_count += 50000\n",
    "                            if genome_type == 'euk': \n",
    "                                euk_count += 1\n",
    "                                contig_5kb_name = \"euk_\" + str(euk_count)\n",
    "                            elif genome_type == 'bact': \n",
    "                                bact_count += 1\n",
    "                                contig_5kb_name = \"bact_\" + str(bact_count)\n",
    "                            contigs.add(contig_5kb_name)\n",
    "                            \n",
    "                            if genome_bp_count < 1000000:\n",
    "                                contig_5kb = record.seq[i:i+50000] \n",
    "                                for j in range(len(contig_5kb)):\n",
    "                                    kmer = contig_5kb[j:j+5].upper()\n",
    "                                    if kmer.reverse_complement() in kmer_list:\n",
    "                                        kmer = kmer.reverse_complement()\n",
    "                                    if len(kmer) == 5:\n",
    "                                        if is_valid_sequence(kmer) is True:\n",
    "                                            kmer_dict[(contig_5kb_name, str(kmer))] += 1\n",
    "                else:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f435d20-3b9c-44b0-b0b4-0c07bc6293a2",
   "metadata": {},
   "source": [
    "Output the results of counts of each 5-mer in each contig in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e7a13-0240-4741-9875-8b9137f2b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"kmer_matrix_validation.tsv\", \"w\")\n",
    "\n",
    "f.write(\"Contig\" + \"\\t\")\n",
    "f.write(\"\\t\".join(contigs))\n",
    "f.write(\"\\n\")\n",
    "for kmer in kmer_list:\n",
    "    f.write(kmer + \"\\t\")\n",
    "    for contig in contigs:\n",
    "        f.write(str(kmer_dict[(contig, kmer)]) + \"\\t\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37e48d-21fd-4633-8e32-8ca02225ea49",
   "metadata": {},
   "source": [
    "Read the kmer count table in as a pandas dataframe, remove contigs with few kmers, and divide each count by the sum of kmer counts on the contig (to get proportional data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ef3258-6917-4347-8a47-0fd642f4d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_df = pd.read_csv(\"kmer_matrix_validation.tsv\", sep=\"\\t\", index_col=False)\n",
    "kmer_df = kmer_df.set_index(\"Contig\")\n",
    "kmer_df = kmer_df.loc[:, kmer_df.sum(axis=0) > 10000]\n",
    "kmer_df = kmer_df.div(kmer_df.sum(axis=0),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b4e08-7ecc-4371-aa7e-0988303e8013",
   "metadata": {},
   "source": [
    "Need to make sure the dataframe is sorted the exact same way as the model was originally run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fb51d9-32ba-4eeb-af19-67fe43255f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_df = kmer_df.reindex(sorted(kmer_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9198ba-ef70-4278-939a-65fe48755d95",
   "metadata": {},
   "source": [
    "Assign labels and prepare a list of lists of 5-mer frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7608956-7e73-4c70-8d99-3ae4b80da36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_kmers = []\n",
    "for column in kmer_df:\n",
    "    kmer_list_contig = kmer_df[column].tolist()\n",
    "    contig_kmers.append(kmer_list_contig)\n",
    "    \n",
    "prelabels = kmer_df.columns.tolist()\n",
    "labels = []\n",
    "for i in prelabels:\n",
    "    if i.split(\"_\")[0] == \"euk\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed163a-39c1-4a51-8835-ad6eaf632396",
   "metadata": {},
   "source": [
    "Perform the predictions and assess accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88177a76-a84b-4740-9dca-f8287004386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the validation set is 99.71014492753623%\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(contig_kmers)\n",
    "print(f\"Accuracy in the validation set is {accuracy_score(labels, predictions) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ba04d-e75c-4e5b-a48d-d4962782014f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
